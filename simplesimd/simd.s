// Code generated by command: go run asm.go -out simd.s -stubs stub.go. DO NOT EDIT.

#include "textflag.h"

// func andSIMD(a []byte, b []byte, res []byte)
TEXT ·andSIMD(SB), NOSPLIT, $0-72
	MOVQ a_base+0(FP), AX
	MOVQ b_base+24(FP), CX
	MOVQ res_base+48(FP), DX
	MOVQ a_len+8(FP), BX

blockloop:
	CMPQ    BX, $0x00000100
	JL      tail
	VMOVUPS (CX), Y0
	VMOVUPS 32(CX), Y1
	VMOVUPS 64(CX), Y2
	VMOVUPS 96(CX), Y3
	VMOVUPS 128(CX), Y4
	VMOVUPS 160(CX), Y5
	VMOVUPS 192(CX), Y6
	VMOVUPS 224(CX), Y7
	VPAND   (AX), Y0, Y0
	VPAND   32(AX), Y1, Y1
	VPAND   64(AX), Y2, Y2
	VPAND   96(AX), Y3, Y3
	VPAND   128(AX), Y4, Y4
	VPAND   160(AX), Y5, Y5
	VPAND   192(AX), Y6, Y6
	VPAND   224(AX), Y7, Y7
	VMOVUPS Y0, (DX)
	VMOVUPS Y1, 32(DX)
	VMOVUPS Y2, 64(DX)
	VMOVUPS Y3, 96(DX)
	VMOVUPS Y4, 128(DX)
	VMOVUPS Y5, 160(DX)
	VMOVUPS Y6, 192(DX)
	VMOVUPS Y7, 224(DX)
	ADDQ    $0x00000100, AX
	ADDQ    $0x00000100, CX
	ADDQ    $0x00000100, DX
	SUBQ    $0x00000100, BX
	JMP     blockloop

tail:
	RET

// func orSIMD(a []byte, b []byte, res []byte)
TEXT ·orSIMD(SB), NOSPLIT, $0-72
	MOVQ a_base+0(FP), AX
	MOVQ b_base+24(FP), CX
	MOVQ res_base+48(FP), DX
	MOVQ a_len+8(FP), BX

blockloop:
	CMPQ    BX, $0x00000100
	JL      tail
	VMOVUPS (CX), Y0
	VMOVUPS 32(CX), Y1
	VMOVUPS 64(CX), Y2
	VMOVUPS 96(CX), Y3
	VMOVUPS 128(CX), Y4
	VMOVUPS 160(CX), Y5
	VMOVUPS 192(CX), Y6
	VMOVUPS 224(CX), Y7
	VPOR    (AX), Y0, Y0
	VPOR    32(AX), Y1, Y1
	VPOR    64(AX), Y2, Y2
	VPOR    96(AX), Y3, Y3
	VPOR    128(AX), Y4, Y4
	VPOR    160(AX), Y5, Y5
	VPOR    192(AX), Y6, Y6
	VPOR    224(AX), Y7, Y7
	VMOVUPS Y0, (DX)
	VMOVUPS Y1, 32(DX)
	VMOVUPS Y2, 64(DX)
	VMOVUPS Y3, 96(DX)
	VMOVUPS Y4, 128(DX)
	VMOVUPS Y5, 160(DX)
	VMOVUPS Y6, 192(DX)
	VMOVUPS Y7, 224(DX)
	ADDQ    $0x00000100, AX
	ADDQ    $0x00000100, CX
	ADDQ    $0x00000100, DX
	SUBQ    $0x00000100, BX
	JMP     blockloop

tail:
	RET

// func andnotSIMD(a []byte, b []byte, res []byte)
TEXT ·andnotSIMD(SB), NOSPLIT, $0-72
	MOVQ a_base+0(FP), AX
	MOVQ b_base+24(FP), CX
	MOVQ res_base+48(FP), DX
	MOVQ a_len+8(FP), BX

blockloop:
	CMPQ    BX, $0x00000100
	JL      tail
	VMOVUPS (CX), Y0
	VMOVUPS 32(CX), Y1
	VMOVUPS 64(CX), Y2
	VMOVUPS 96(CX), Y3
	VMOVUPS 128(CX), Y4
	VMOVUPS 160(CX), Y5
	VMOVUPS 192(CX), Y6
	VMOVUPS 224(CX), Y7
	VPANDN  (AX), Y0, Y0
	VPANDN  32(AX), Y1, Y1
	VPANDN  64(AX), Y2, Y2
	VPANDN  96(AX), Y3, Y3
	VPANDN  128(AX), Y4, Y4
	VPANDN  160(AX), Y5, Y5
	VPANDN  192(AX), Y6, Y6
	VPANDN  224(AX), Y7, Y7
	VMOVUPS Y0, (DX)
	VMOVUPS Y1, 32(DX)
	VMOVUPS Y2, 64(DX)
	VMOVUPS Y3, 96(DX)
	VMOVUPS Y4, 128(DX)
	VMOVUPS Y5, 160(DX)
	VMOVUPS Y6, 192(DX)
	VMOVUPS Y7, 224(DX)
	ADDQ    $0x00000100, AX
	ADDQ    $0x00000100, CX
	ADDQ    $0x00000100, DX
	SUBQ    $0x00000100, BX
	JMP     blockloop

tail:
	RET

// func andScalar(a []byte, b []byte, res []byte)
TEXT ·andScalar(SB), NOSPLIT, $0-72
	MOVQ a_base+0(FP), AX
	MOVQ b_base+24(FP), CX
	MOVQ res_base+48(FP), DX
	MOVQ a_len+8(FP), BX
	XORQ BP, BP

loop:
	// Loop until zero bytes remain.
	CMPQ BX, $0x00
	JE   done
	MOVQ (CX), BP
	ANDQ (AX), BP
	MOVQ BP, (DX)
	ADDQ $0x00000008, AX
	ADDQ $0x00000008, CX
	ADDQ $0x00000008, DX
	SUBQ $0x00000008, BX
	JMP  loop

done:
	RET

// func orScalar(a []byte, b []byte, res []byte)
TEXT ·orScalar(SB), NOSPLIT, $0-72
	MOVQ a_base+0(FP), AX
	MOVQ b_base+24(FP), CX
	MOVQ res_base+48(FP), DX
	MOVQ a_len+8(FP), BX
	XORQ BP, BP

loop:
	// Loop until zero bytes remain.
	CMPQ BX, $0x00
	JE   done
	MOVQ (CX), BP
	ORQ  (AX), BP
	MOVQ BP, (DX)
	ADDQ $0x00000008, AX
	ADDQ $0x00000008, CX
	ADDQ $0x00000008, DX
	SUBQ $0x00000008, BX
	JMP  loop

done:
	RET

// func andnotScalar(a []byte, b []byte, res []byte)
TEXT ·andnotScalar(SB), NOSPLIT, $0-72
	MOVQ a_base+0(FP), AX
	MOVQ b_base+24(FP), CX
	MOVQ res_base+48(FP), DX
	MOVQ a_len+8(FP), BX
	XORQ BP, BP

loop:
	// Loop until zero bytes remain.
	CMPQ  BX, $0x00
	JE    done
	MOVQ  (CX), BP
	ANDNQ (AX), BP, BP
	MOVQ  BP, (DX)
	ADDQ  $0x00000008, AX
	ADDQ  $0x00000008, CX
	ADDQ  $0x00000008, DX
	SUBQ  $0x00000008, BX
	JMP   loop

done:
	RET
